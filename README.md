# ğŸŒ¦ï¸ End-to-End Weather Data Pipeline (Airflow + Postgres + dbt + Docker)

Pipeline **ETL/ELT** conteneurisÃ© qui :
- **extrait** des observations mÃ©tÃ©o depuis lâ€™API *Weatherstack* (Python),
- **charge** les donnÃ©es brutes dans un **PostgreSQL** `warehouse`,
- **transforme** les donnÃ©es avec **dbt** (staging â†’ dimension/fact â†’ mÃ©triques),
- est **orchestrÃ©** par **Apache Airflow** via **Astro CLI**,
- sâ€™exÃ©cute en **Docker** grÃ¢ce Ã  `docker-compose.override.yml`.

![Architecture](weather_data_pipeline.jpeg)

---

## ğŸ§± Stack
- **Docker / docker-compose** â€“ conteneurisation & rÃ©seau local
- **Astro CLI** â€“ Airflow prÃªt Ã  lâ€™emploi en local
- **Airflow** â€“ orchestration des DAGs
- **PostgreSQL (warehouse)** â€“ stockage des donnÃ©es
- **dbt (core + postgres adapter)** â€“ transformations SQL

---

## ğŸ“ Structure du repo
```
.
â”œâ”€ dags/
â”‚  â”œâ”€ extract_weather.py          # DAG d'extract & load (API â†’ warehouse)
â”‚  â”œâ”€ dbt_run.py                  # DAG pour dbt run + test
â”‚  â””â”€ analytics_weather.py        # (optionnel) DAG pour les mÃ©triques dbt
â”œâ”€ weather_dbt/                   # Projet dbt
â”‚  â”œâ”€ models/
â”‚  â”‚  â”œâ”€ staging/...
â”‚  â”‚  â””â”€ marts/...
â”‚  â”œâ”€ dbt_project.yml
â”‚  â””â”€ packages.yml
â”œâ”€ docker-compose.override.yml    # ajoute le service Postgres warehouse
â”œâ”€ requirements.txt               # libs Airflow image (dbt, psycopg2â€¦)
â”œâ”€ Dockerfile                     # image Astro Runtime personnalisÃ©e
â”œâ”€ .env.example                   # variables d'env Ã  copier/adapter
â”œâ”€ .gitignore
â””â”€ README.md
```

---

## ğŸ” Variables dâ€™environnement

CrÃ©e un fichier **`.env`** Ã  la racine Ã  partir de **`.env.example`**Â :

```bash
cp .env.example .env
# puis Ã©dite .env (clÃ© API, etc.)
```

Variables utilisÃ©es (extrait)Â :
```dotenv
# Airflow internal Postgres (fourni par Astro)
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=airflow

# Warehouse Postgres (notre entrepÃ´t)
WAREHOUSE_USER=warehouse
WAREHOUSE_PASSWORD=warehouse
WAREHOUSE_DB=weather
WAREHOUSE_PORT=5433
WAREHOUSE_HOST=warehouse

# API
WEATHERSTACK_API_KEY=CHANGE_ME
```

> â„¹ï¸ **Astro** charge automatiquement `.env` si tu lâ€™indiques avec `--env .env`.

---

## ğŸ³ Docker & Compose

Le fichier **`docker-compose.override.yml`** (fourni) **ajoute** un conteneur **Postgres 14** pour le *warehouse* et monte le projet dbt dans les conteneurs Airflow.

> Extrait clÃ©Â :
```yaml
services:
  warehouse:
    image: postgres:14
    env_file:
      - .env
    environment:
      POSTGRES_USER: ${WAREHOUSE_USER}
      POSTGRES_PASSWORD: ${WAREHOUSE_PASSWORD}
      POSTGRES_DB: ${WAREHOUSE_DB}
    ports:
      - "5433:5432"
    volumes:
      - warehouse_data:/var/lib/postgresql/data
```

**Pourquoi 5433 ?** Pour Ã©viter le conflit avec le Postgres interne dâ€™Airflow (5432).

---

## â–¶ï¸ Lancer le projet (Astro + Docker)

1) **Installer** prÃ©requis  
- Docker Desktop
- Astro CLI

2) **Construire et dÃ©marrer** (en chargeant `.env`)Â :
```bash
astro dev start --no-cache --wait 180s --env .env
```

3) **URLs**  
- Airflow UI â†’ http://localhost:8080 (admin / admin par dÃ©faut)
- Postgres warehouse â†’ `localhost:5433`

4) **ArrÃªter**  
```bash
astro dev stop
```

---

## ğŸš€ ExÃ©cuter les DAGs

Dans lâ€™UI AirflowÂ :
- **extract_weather** â†’ rÃ©cupÃ¨re la mÃ©tÃ©o (Paris) et insÃ¨re en `raw_weather`.
- **dbt_run** â†’ `dbt run` puis `dbt test` sur le projet `weather_dbt`.
- **analytics_weather** *(optionnel)* â†’ calcule et teste `weather_metrics`.

---

## ğŸ§  dbt â€“ structure & commandes utiles

ModÃ¨les clÃ©sÂ :
- `models/staging/stg_weather.sql` â€“ projection/renommage + tests de qualitÃ©
- `models/marts/dim_city.sql` â€“ dimension
- `models/marts/fact_weather.sql` â€“ faits par observation
- `models/marts/weather_metrics.sql` â€“ moyennes/jours, anomalies mensuelles, **humidex**

ExÃ©cuter dbt **dans le scheduler**Â :
```bash
docker exec -it $(docker ps -qf "name=scheduler") bash
dbt debug --project-dir /usr/app/weather_dbt --profiles-dir /usr/app
dbt run   --project-dir /usr/app/weather_dbt --profiles-dir /usr/app
dbt test  --project-dir /usr/app/weather_dbt --profiles-dir /usr/app
```

> Dans les DAGs, on passe aussi `--no-write-json --log-format text --log-path /tmp --target-path /tmp/target` pour Ã©viter des problÃ¨mes de permissions en Ã©criture.

---

## ğŸ§ª Validation rapide

- `select * from analytics.stg_weather limit 5;`
- `select * from analytics.dim_city limit 5;`
- `select * from analytics.fact_weather limit 5;`
- `select * from analytics.analytics.weather_metrics limit 5;` *(si DAG analytics activÃ©)*

---

## ğŸ› ï¸ DÃ©pannage (FAQ)

- **Le conteneur `warehouse` boucle au dÃ©marrage / demande un mot de passe**  
  âœ Assure-toi que **`.env`** est chargÃ© par Astro: `astro dev start --env .env`  
  âœ VÃ©rifie que le volume `warehouse_data` a bien Ã©tÃ© recrÃ©Ã© si tu as changÃ© les secrets.

- **dbt ne se connecte pas**  
  âœ Dans `profiles.yml` (cÃ´tÃ© conteneurs Airflow), utilise `host: warehouse` et `port: 5432`.  
  âœ Depuis lâ€™hÃ´te (tests rapides), utilise `host.docker.internal:5433`.

- **Erreurs de permissions dbt**  
  âœ Utilise `--no-write-json`, `--log-path /tmp`, `--target-path /tmp/target` (dÃ©jÃ  dans les DAGs).

---

## ğŸ“œ Licence
Ce dÃ©pÃ´t est fourni Ã  titre Ã©ducatif et peut Ãªtre rÃ©utilisÃ©/Ã©tendu librement dans le cadre de projets dâ€™apprentissage.
